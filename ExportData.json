{
  "Tool": [],
  "ChatFlow": [
    {
      "id": "0da1547f-1869-462b-99f4-f51105cbf0e4",
      "name": "Belajar-APA1",
      "flowData": "{\n  \"nodes\": [\n    {\n      \"id\": \"openAI_0\",\n      \"position\": {\n        \"x\": 1221.9743387434564,\n        \"y\": 50.40075565444525\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"openAI_0\",\n        \"label\": \"OpenAI\",\n        \"version\": 4,\n        \"name\": \"openAI\",\n        \"type\": \"OpenAI\",\n        \"baseClasses\": [\n          \"OpenAI\",\n          \"BaseLLM\",\n          \"BaseLanguageModel\",\n          \"Runnable\"\n        ],\n        \"category\": \"LLMs\",\n        \"description\": \"Wrapper around OpenAI large language models\",\n        \"inputParams\": [\n          {\n            \"label\": \"Connect Credential\",\n            \"name\": \"credential\",\n            \"type\": \"credential\",\n            \"credentialNames\": [\n              \"openAIApi\"\n            ],\n            \"id\": \"openAI_0-input-credential-credential\"\n          },\n          {\n            \"label\": \"Model Name\",\n            \"name\": \"modelName\",\n            \"type\": \"asyncOptions\",\n            \"loadMethod\": \"listModels\",\n            \"default\": \"gpt-3.5-turbo-instruct\",\n            \"id\": \"openAI_0-input-modelName-asyncOptions\"\n          },\n          {\n            \"label\": \"Temperature\",\n            \"name\": \"temperature\",\n            \"type\": \"number\",\n            \"step\": 0.1,\n            \"default\": 0.7,\n            \"optional\": true,\n            \"id\": \"openAI_0-input-temperature-number\"\n          },\n          {\n            \"label\": \"Max Tokens\",\n            \"name\": \"maxTokens\",\n            \"type\": \"number\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"openAI_0-input-maxTokens-number\"\n          },\n          {\n            \"label\": \"Top Probability\",\n            \"name\": \"topP\",\n            \"type\": \"number\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"openAI_0-input-topP-number\"\n          },\n          {\n            \"label\": \"Best Of\",\n            \"name\": \"bestOf\",\n            \"type\": \"number\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"openAI_0-input-bestOf-number\"\n          },\n          {\n            \"label\": \"Frequency Penalty\",\n            \"name\": \"frequencyPenalty\",\n            \"type\": \"number\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"openAI_0-input-frequencyPenalty-number\"\n          },\n          {\n            \"label\": \"Presence Penalty\",\n            \"name\": \"presencePenalty\",\n            \"type\": \"number\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"openAI_0-input-presencePenalty-number\"\n          },\n          {\n            \"label\": \"Batch Size\",\n            \"name\": \"batchSize\",\n            \"type\": \"number\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"openAI_0-input-batchSize-number\"\n          },\n          {\n            \"label\": \"Timeout\",\n            \"name\": \"timeout\",\n            \"type\": \"number\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"openAI_0-input-timeout-number\"\n          },\n          {\n            \"label\": \"BasePath\",\n            \"name\": \"basepath\",\n            \"type\": \"string\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"openAI_0-input-basepath-string\"\n          },\n          {\n            \"label\": \"BaseOptions\",\n            \"name\": \"baseOptions\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"openAI_0-input-baseOptions-json\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Cache\",\n            \"name\": \"cache\",\n            \"type\": \"BaseCache\",\n            \"optional\": true,\n            \"id\": \"openAI_0-input-cache-BaseCache\"\n          }\n        ],\n        \"inputs\": {\n          \"cache\": \"\",\n          \"modelName\": \"gpt-3.5-turbo-instruct\",\n          \"temperature\": 0.7,\n          \"maxTokens\": \"\",\n          \"topP\": \"\",\n          \"bestOf\": \"\",\n          \"frequencyPenalty\": \"\",\n          \"presencePenalty\": \"\",\n          \"batchSize\": \"\",\n          \"timeout\": \"\",\n          \"basepath\": \"\",\n          \"baseOptions\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"openAI_0-output-openAI-OpenAI|BaseLLM|BaseLanguageModel|Runnable\",\n            \"name\": \"openAI\",\n            \"label\": \"OpenAI\",\n            \"description\": \"Wrapper around OpenAI large language models\",\n            \"type\": \"OpenAI | BaseLLM | BaseLanguageModel | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 574,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 1221.9743387434564,\n        \"y\": 50.40075565444525\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"llmChain_0\",\n      \"position\": {\n        \"x\": 1621.302138619784,\n        \"y\": 608.9289348499042\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"llmChain_0\",\n        \"label\": \"LLM Chain\",\n        \"version\": 3,\n        \"name\": \"llmChain\",\n        \"type\": \"LLMChain\",\n        \"baseClasses\": [\n          \"LLMChain\",\n          \"BaseChain\",\n          \"Runnable\"\n        ],\n        \"category\": \"Chains\",\n        \"description\": \"Chain to run queries against LLMs\",\n        \"inputParams\": [\n          {\n            \"label\": \"Chain Name\",\n            \"name\": \"chainName\",\n            \"type\": \"string\",\n            \"placeholder\": \"Name Your Chain\",\n            \"optional\": true,\n            \"id\": \"llmChain_0-input-chainName-string\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Language Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseLanguageModel\",\n            \"id\": \"llmChain_0-input-model-BaseLanguageModel\"\n          },\n          {\n            \"label\": \"Prompt\",\n            \"name\": \"prompt\",\n            \"type\": \"BasePromptTemplate\",\n            \"id\": \"llmChain_0-input-prompt-BasePromptTemplate\"\n          },\n          {\n            \"label\": \"Output Parser\",\n            \"name\": \"outputParser\",\n            \"type\": \"BaseLLMOutputParser\",\n            \"optional\": true,\n            \"id\": \"llmChain_0-input-outputParser-BaseLLMOutputParser\"\n          },\n          {\n            \"label\": \"Input Moderation\",\n            \"description\": \"Detect text that could generate harmful output and prevent it from being sent to the language model\",\n            \"name\": \"inputModeration\",\n            \"type\": \"Moderation\",\n            \"optional\": true,\n            \"list\": true,\n            \"id\": \"llmChain_0-input-inputModeration-Moderation\"\n          }\n        ],\n        \"inputs\": {\n          \"model\": \"{{openAI_0.data.instance}}\",\n          \"prompt\": \"{{promptTemplate_0.data.instance}}\",\n          \"outputParser\": \"\",\n          \"inputModeration\": \"\",\n          \"chainName\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"name\": \"output\",\n            \"label\": \"Output\",\n            \"type\": \"options\",\n            \"description\": \"\",\n            \"options\": [\n              {\n                \"id\": \"llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable\",\n                \"name\": \"llmChain\",\n                \"label\": \"LLM Chain\",\n                \"description\": \"\",\n                \"type\": \"LLMChain | BaseChain | Runnable\"\n              },\n              {\n                \"id\": \"llmChain_0-output-outputPrediction-string|json\",\n                \"name\": \"outputPrediction\",\n                \"label\": \"Output Prediction\",\n                \"description\": \"\",\n                \"type\": \"string | json\"\n              }\n            ],\n            \"default\": \"llmChain\"\n          }\n        ],\n        \"outputs\": {\n          \"output\": \"llmChain\"\n        },\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 508,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 1621.302138619784,\n        \"y\": 608.9289348499042\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"promptTemplate_0\",\n      \"position\": {\n        \"x\": 804.8791900754329,\n        \"y\": 508.2025728117968\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"promptTemplate_0\",\n        \"label\": \"Prompt Template\",\n        \"version\": 1,\n        \"name\": \"promptTemplate\",\n        \"type\": \"PromptTemplate\",\n        \"baseClasses\": [\n          \"PromptTemplate\",\n          \"BaseStringPromptTemplate\",\n          \"BasePromptTemplate\",\n          \"Runnable\"\n        ],\n        \"category\": \"Prompts\",\n        \"description\": \"Schema to represent a basic prompt for an LLM\",\n        \"inputParams\": [\n          {\n            \"label\": \"Template\",\n            \"name\": \"template\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"placeholder\": \"What is a good name for a company that makes {product}?\",\n            \"id\": \"promptTemplate_0-input-template-string\"\n          },\n          {\n            \"label\": \"Format Prompt Values\",\n            \"name\": \"promptValues\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"acceptVariable\": true,\n            \"list\": true,\n            \"id\": \"promptTemplate_0-input-promptValues-json\"\n          }\n        ],\n        \"inputAnchors\": [],\n        \"inputs\": {\n          \"template\": \"Tell me a joke about horses.\",\n          \"promptValues\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable\",\n            \"name\": \"promptTemplate\",\n            \"label\": \"PromptTemplate\",\n            \"description\": \"Schema to represent a basic prompt for an LLM\",\n            \"type\": \"PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 513,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 804.8791900754329,\n        \"y\": 508.2025728117968\n      },\n      \"dragging\": false\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"openAI_0\",\n      \"sourceHandle\": \"openAI_0-output-openAI-OpenAI|BaseLLM|BaseLanguageModel|Runnable\",\n      \"target\": \"llmChain_0\",\n      \"targetHandle\": \"llmChain_0-input-model-BaseLanguageModel\",\n      \"type\": \"buttonedge\",\n      \"id\": \"openAI_0-openAI_0-output-openAI-OpenAI|BaseLLM|BaseLanguageModel|Runnable-llmChain_0-llmChain_0-input-model-BaseLanguageModel\"\n    },\n    {\n      \"source\": \"promptTemplate_0\",\n      \"sourceHandle\": \"promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable\",\n      \"target\": \"llmChain_0\",\n      \"targetHandle\": \"llmChain_0-input-prompt-BasePromptTemplate\",\n      \"type\": \"buttonedge\",\n      \"id\": \"promptTemplate_0-promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_0-llmChain_0-input-prompt-BasePromptTemplate\"\n    }\n  ]\n}",
      "type": "CHATFLOW"
    }
  ],
  "AgentFlow": [],
  "Variable": [],
  "Assistant": []
}